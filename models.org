#+TITLE: Model notes
#+AUTHOR: Abhinav Tushar

* Ensemble specifications

** Inputs
Following are possible inputs to the ensemble models.

1. /Point predictions/ from component models

   This could be extended to values from past /n/ weeks.

2. /Full probability distributions/ from component models

   Since the output can have large number of bins (nodes), the distributions can
   be encoded in a shorter form using either:

   - Simple summary statistics

   - An autoencoder trained in an unsupervised manner (feed forward or
     convolution)

   - Similar model as above but trained as a part of the main model, in a
     supervised setting.

   This can also be extended to distributions from past /n/ weeks.

3. /Week/ of the input

   This provides an indication of which regime we are working in as far as
   seasonal patterns as concerned. Since using direct numbers will make it out
   of scale and makes the series discontinuous at ends (last week = 53, next
   week = 1), weeks can be encoded using a clock model. Weeks go as degrees
   in a circle (~\theta~) and the input to the model can be ~[sin(\theta), cos(\theta)]~.

   Alternatively, week information can itself be modeled using actual values
   corresponding to week numbers. This model can provide the necessary encoding.

   This can also be extended to use past /n/ weeks depending on the first two
   inputs.

4. /Actual data/

   Actual data for past weeks (possibly more than 1 week).

** Output

Output from the ensemble at each time step is probability distribution for /x/
week ahead predictions. This can be provided using a final softmax layer, where
each node represents probability for each of the bins in the output
distribution. Another option is to output statistics for N component mixture
model from the final layer. This can help reduce the number of nodes in the
output layer as well as provide an added smoothing effect controllable by the
value of N.

* Models / Components

** Simple feed forward
Takes in the described four input and predicts distribution. Can be further
augmented by input distribution / week encoding branch.

** Probability autoencoder
Summarize probability distributions using CNNs or fully connected networks.

** Week embedder
Learn week embeddings using the actual wili values at the corresponding points.

** Residual based
Fit the residual of component model predictions.
