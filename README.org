#+TITLE: Neural Stack

Neural network based ensemble of flu prediction models.

Experiments are kept in ~./notebooks~. Non-notebook code lies in ~./src~. Helper
scripts for snakemake are in ~./scripts~.

** Steps to reproduce
#+BEGIN_SRC bash
# Clone the repository with submodules
git clone git@github.com:reichlab/neural-stack --recursive
cd neural-stack

# Setup dependencies
pip install pipenv
pipenv install

# Preprocess data for the two experiments
# See last section of this readme for experiment description
pipenv run snakemake get_lab_data
pipenv run snakemake get_collaborative_data

# Edit config to select the experiment to run
eval $EDITOR config.yaml

# Generate results from non-notebook models
pipenv run snakemake generate_component_scores
pipenv run snakemake generate_product_scores
pipenv run snakemake generate_dem_scores
#+END_SRC

* Data

Ensemble models work on US flu data from [[https://www.cdc.gov/flu/weekly/index.htm][CDC]]. The data (actual and predictions)
are organized in both temporal and spatial dimension. Spatially, there are data
points for [[https://www.hhs.gov/about/agencies/iea/regional-offices/index.html][10 HHS regions]] (identified by ~nat~, ~hhs1~, ~hhs2~ etc.). Temporally, data
points are assigned a time identifier which looks like ~200323~. The first four
digits identify the year and the next two identify the epiweek (this is the MMWR
week). Thus ~200323~ means epiweek /23/ for year /2003/.

There are two type of data files needed by the models.

1. *Actual data*

   This is a collection of rows specifying actual /wILI/ values for a given region
   and time identifier (see above).

   The dataframe looks like this

   | epiweek | region |            wili |
   |---------+--------+-----------------|
   |  199740 | nat    | 1.1014825590386 |
   |  199741 | nat    | 1.2000682166927 |
   

2. *Prediction file for each model*

   Each model provides individual files with matrix data (~numpy.savetxt~ format),
   the rows of which are mapped to a region and time using a separate ~identifier~
   file (a csv with "epiweek" and "region" columns). The matrix files contain
   week ahead predictions and special target predictions like /peak week/.

   Each wili target (week ahead targets and peak wili target) has 131 bins. 130
   bins as follows [0.0, 0.1), [0.1, 0.2) ... [12.9, 13.0) and one bin for
   values in [13.0, 100] (we skip this while modelling).

   For /onset week/, we have 34 bins. 33 of these represent the weeks, while the
   last one represents bin for /no/ onset. /Peak week/ just has 33 bins representing
   the weeks. As of now, these bins are spread over the internally used /season/
   representation and needs some transformation for starting at the mmwr week 1
   for each year.

* Ensemble specifications

** Input

Following are possible inputs to the ensemble models. Not all inputs are going
to helpful. This section just tries to document the possibilities.

1. /Point predictions/ from component models

2. /Full probability distributions/ from component models

   Predictions from a component model are discrete probability distributions,
   these can be used instead of the point predictions as above. See
   ~./notebooks/encoding-distribution~ for more details on ways we represent the
   distributions in models.

3. /Week/ of the input

   This provides an indication of which regime we are working in as far as
   seasonal patterns as concerned. See notebooks inside
   ~./notebooks/encoding-week~ for possible approaches.

4. /Log scores of model predictions/

   Log scores of models provide a simple way to connect current week to the
   model accuracy. This can be used to learn weights for component models
   depending on the time of year.

5. /Actual data for past weeks/

All of these inputs can be extended by using past values. For example, instead
of taking just the current prediction, the ensemble model can take past /n/ week
predictions.

** Output

Output from the ensemble at each time step is a probability distribution for /x/
week ahead predictions. Other targets are /onset week/, /peak week/ and /peak value/.
These are also represented as probability distributions so most of the ideas
work similarly.

* Models

This section contains descriptions of models currently working in this
repository.

** Mixture Density Network

Notebooks ~./notebooks/*-mixture-density-network*.ipynb~ use a simple mixture
density network to predict a mixture of normal distributions to provide the
target distributions.

** Convolutional Networks

Notebooks ~./notebooks/*cnn*.ipynb~ use convolutional layers to model the full
probability distribution directly.

** Residual fit network

Residual model trains a neural network on the residual we get after fitting the
component models to actual data, resulting in an overall summation based
ensemble. The notebook for this is ~./notebooks/2.0-fitting-residuals.ipynb~.

* Experiments for paper

The following section documents two experiments to run to test our the neural
network ensembles.

** A: FluSightNetwork models (2010/2011 - 2016/2017)
    
Experiment name ~collaborative~

- 4 training seasons, 3 testing
- using all component models from FluSightNetwork
- component model forecasts are made on unrevised data prospectively
- NN training/selection: Leave one season out cross validation is used
  hyperparameter tuning.
- ensembles to compare: EW, CW, NN1, NN2 (i.e. two neural network specifications
  based on selection in training phase)
    
** B: CDC Flu forecasting based on Evan's paper (1997/1998 - 2015/2016)

Experiment name ~lab~

- 14 training, 5 test seasons
- 3 component models (KDE, KCDE, SARIMA)
- component model forecasts made on revised data and in training phase are done
  using LOSO
- NN training/selection: Leave one season out cross validation is used
  hyperparameter tuning.
- ensembles to compare: EW, CW, FW-reg-w (?), NN1, NN2
