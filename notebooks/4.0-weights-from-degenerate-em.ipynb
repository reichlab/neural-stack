{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degenerate EM weights\n",
    "\n",
    "This notebook generates weights for models using the degenerate EM method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils.data as udata\n",
    "import utils.dists as udists\n",
    "import utils.misc as u\n",
    "import models\n",
    "import os\n",
    "import losses\n",
    "from jrun import jin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate 5 type of weights for the models.\n",
    "1. Equal weights. This assigns equal weight to each model.\n",
    "2. Constant weights. This uses training data for all seasons, region and targets to assign one weight for each model.\n",
    "3. Target based weights. This uses data chunks for all season, regions but separate targets.\n",
    "4. Target type weights. Similar to target based weights but with target grouped in seasonal and week ahead.\n",
    "5. Target and region based weights. Similar to target based weights but with another separation in region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = jin(\"exp\", \"seasons-4-to-3\")\n",
    "COMPONENTS = jin(\"components\", u.available_models(\"../data\"))\n",
    "TEST_SPLIT_THRESH = jin(\"splitweek\", 201443)\n",
    "OUTPUT_DIR = u.ensure_dir(f\"../weights/{EXP_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Component:\n",
    "    \"\"\"\n",
    "    Helper class for working with components\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.loader = udata.ComponentDataLoader(\"../data\", name)\n",
    "components = [Component(name) for name in COMPONENTS]\n",
    "actual_dl = udata.ActualDataLoader(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Equal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame({\n",
    "    \"model\": [c.name for c in components],\n",
    "    \"weight\": [1/len(components) for c in components]\n",
    "})\n",
    "weights.to_csv(f\"{OUTPUT_DIR}/equal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constant weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Need to collect scores for every target\n",
    "scores = []\n",
    "for week in [1, 2, 3, 4]:\n",
    "    y, Xs, yi = udata.get_week_ahead_training_data(\n",
    "        week, None,\n",
    "        actual_dl, [c.loader for c in components]\n",
    "    )\n",
    "    # Use only the training data\n",
    "    train_indices = yi[:, 0] < TEST_SPLIT_THRESH\n",
    "    scores.append(udists.score_predictions([X[train_indices] for X in Xs], y[train_indices]))\n",
    "    \n",
    "for s_target in [\"peak\", \"peak_wk\", \"onset_wk\"]:\n",
    "    y, Xs, yi = udata.get_seasonal_training_data(\n",
    "        s_target, None,\n",
    "        actual_dl, [c.loader for c in components]\n",
    "    )\n",
    "    # Use only the training data\n",
    "    train_indices = yi[:, 0] < TEST_SPLIT_THRESH\n",
    "    scores.append(udists.score_predictions([X[train_indices] for X in Xs], y[train_indices]))\n",
    "    \n",
    "scores = np.concatenate(scores, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame({\n",
    "    \"model\": [c.name for c in components],\n",
    "    \"weight\": models.dem(np.exp(scores))\n",
    "})\n",
    "weights.to_csv(f\"{OUTPUT_DIR}/constant.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target based weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target type weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Target and region weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
