{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture Density Network\n",
    "\n",
    "This notebook trains a simple gaussian mixture density network from basic statistics of the predictive distributions coming from the component models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data\n",
    "import utils\n",
    "import losses\n",
    "\n",
    "from functools import partial, reduce\n",
    "\n",
    "from keras.layers import (Activation, Dense, Dropout, Embedding, Flatten, Merge, Reshape)\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Component:\n",
    "    \"\"\"\n",
    "    Helper class for working with components\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.loader = data.ComponentDataLoader(\"../data\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "components = [Component(name) for name in [\n",
    "    \"ReichLab-KCDE\",\n",
    "    \"Delphi-EmpiricalFuture\",\n",
    "    \"ReichLab-SARIMA1\",\n",
    "    \"CU-EAKFC\"\n",
    "]]\n",
    "actual_dl = data.ActualDataLoader(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on week ahead predictions\n",
    "\n",
    "We need to take the common row entries (common \"epiweek\", \"region\") for each data item, i.e. actual data and component data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REGION = None # Specify None for using all the data\n",
    "WEEK_NUMBER = 1\n",
    "\n",
    "y, Xs, yi = data.get_week_ahead_training_data(\n",
    "    WEEK_NUMBER, REGION,\n",
    "    actual_dl, [cmp.loader for cmp in components]\n",
    ")\n",
    "\n",
    "for idx, cmp in enumerate(components):\n",
    "    cmp.data = Xs[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting statistical features from the distributions\n",
    "\n",
    "We are just using the mean and std of distributions and concatenating to a single vector as input to the model.\n",
    "\n",
    "*X* refers to combined features from all the models.\n",
    "\n",
    "*X_[model]* refers to full distributions from a particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = utils.get_merged_features(\n",
    "    Xs, \n",
    "    [utils.dist_mean, utils.dist_std]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split based on year\n",
    "We take items before epiweek *201443* as train and rest as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = yi[:, 0] < 201443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model is a simple mixture density network which returns a set of parameters which are then used in the loss function to get the negative log score for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mdn(n_input, n_mix):\n",
    "    \"\"\"\n",
    "    Return a mixture density model with given number of mixtures (gaussians)\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_shape=(n_input,)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(10))\n",
    "#     model.add(Activation(\"relu\"))\n",
    "#     model.add(Dense(5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    # Return 3 parameters, mu, sigma and mixture weight\n",
    "    model.add(Dense(n_mix * 3))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_MIX = 1\n",
    "loss_fn = partial(losses.mdn_loss, n_mix=N_MIX)\n",
    "loss_fn.__name__ = \"mdn_loss\" # Keras needs a name for function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model generator\n",
    "def gen_model():\n",
    "    return mdn(X.shape[1], N_MIX)\n",
    "\n",
    "def train_model(model, train_data, val_data):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=loss_fn)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=4, mode=\"auto\")\n",
    "\n",
    "    history = model.fit(train_data[0],\n",
    "                        train_data[1],\n",
    "                        batch_size=64, epochs=100,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stop],\n",
    "                        validation_data=val_data)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[model, mean_losses, cv_metadata, final_history] = utils.cv_train(\n",
    "    gen_model, train_model,\n",
    "    X[train_indices], y[train_indices],\n",
    "    k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regions = [\"nat\", *[f\"hhs{i}\" for i in range(1, 11)], None]\n",
    "\n",
    "models = [*[cmp.name for cmp in components], \"n-ensemble\", \"ave-ensemble\", \"prod-ensemble\"]\n",
    "\n",
    "eval_df = {model: [] for model in models}\n",
    "\n",
    "for region in regions:\n",
    "    if region is None:\n",
    "        eval_indices = ~train_indices\n",
    "    else:\n",
    "        eval_indices = (~train_indices) & (yi[:, 1] == region)\n",
    "        \n",
    "    component_dists = [cmp.data[eval_indices] for cmp in components]\n",
    "    n_dist = utils.mdn_params_to_dists(model.predict(X[eval_indices]))\n",
    "    ave_dist = np.mean(component_dists, axis=0)\n",
    "    \n",
    "    prod_dist = reduce(np.multiply, component_dists)\n",
    "    prod_dist /= prod_dist.sum(axis=0) + K.epsilon()\n",
    "\n",
    "    dists = [\n",
    "        *component_dists,\n",
    "        n_dist,\n",
    "        ave_dist,\n",
    "        prod_dist\n",
    "    ]\n",
    "    y_one_hot = utils.wili_to_dists(y[eval_indices])\n",
    "    \n",
    "    for name, output in zip(models, dists):\n",
    "        eval_df[name].append(K.categorical_crossentropy(output, y_one_hot).mean().eval())\n",
    "eval_df = pd.DataFrame(eval_df)\n",
    "eval_df.index = [*regions[:-1], \"All\"]\n",
    "eval_df.to_csv(f\"{WEEK_NUMBER}_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot random predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sample few of the examples\n",
    "n_plots = 5\n",
    "plot_indices = np.random.randint(0, y[~train_indices].shape[0], size=n_plots)\n",
    "\n",
    "y_plot_out = y[~train_indices][plot_indices]\n",
    "\n",
    "component_dists = [cmp.data[~train_indices][plot_indices] for cmp in components]\n",
    "\n",
    "n_dist = utils.mdn_params_to_dists(model.predict(X[~train_indices][plot_indices]))\n",
    "ave_dist = np.mean(component_dists, axis=0)\n",
    "prod_dist = reduce(np.multiply, component_dists)\n",
    "prod_dist /= prod_dist.sum(axis=0) + K.epsilon()\n",
    "\n",
    "dists = [*component_dists, n_dist, ave_dist, prod_dist]\n",
    "\n",
    "bins = np.linspace(0, 12.9, 130)\n",
    "models = [*[cmp.name for cmp in components], \"n-ensemble\", \"ave-ensemble\", \"prod-ensemble\"]\n",
    "\n",
    "for pidx in range(n_plots):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    for idx, model in enumerate(models):\n",
    "        plt.plot(bins, dists[idx][pidx], label=model)\n",
    "    \n",
    "    # Plot actual line\n",
    "    plt.axvline(x=y_plot_out[i])\n",
    "    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
