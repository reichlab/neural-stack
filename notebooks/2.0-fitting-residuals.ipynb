{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual fitting\n",
    "\n",
    "This notebook trains a neural network to fit residuals left after a component model is trained. The ensemble model here takes a prediction distribution from a single component model and tries to fit the error using the actual data and the peak of the distribution.\n",
    "\n",
    "NOTE: This is an old notebook and will not work with current structure of repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils.data as udata\n",
    "import utils.dists as udists\n",
    "import utils.misc as u\n",
    "import os\n",
    "import losses\n",
    "import pymmwr\n",
    "\n",
    "from functools import partial\n",
    "from jrun import jin\n",
    "from keras.layers import (Activation, Dense, Dropout, Embedding, Flatten, Merge, Reshape)\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXP_NAME = jin(\"exp\", \"residual/seasons-14-to-5\")\n",
    "COMPONENT = jin(\"component\", \"sarima\")\n",
    "WEEK_NUMBER = jin(\"week\", 4)\n",
    "TEST_SPLIT_THRESH = jin(\"splitweek\", 201143)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Component:\n",
    "    \"\"\"\n",
    "    Helper class for working with components\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.loader = udata.ComponentDataLoader(\"../data\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "component = Component(COMPONENT)\n",
    "actual_dl = udata.ActualDataLoader(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on week ahead predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = None # Specify None for using all the data\n",
    "\n",
    "y, Xs, yi = udata.get_week_ahead_training_data(\n",
    "    WEEK_NUMBER, REGION,\n",
    "    actual_dl, [component.loader]\n",
    ")\n",
    "\n",
    "component.data = Xs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting error using the distribution max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "component_out = udists.get_merged_features(\n",
    "    Xs,\n",
    "    [udists.dist_median]\n",
    ")[:, 0]\n",
    "\n",
    "component_error = y - component_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network inputs and outputs\n",
    "\n",
    "The network will take distribution peak from the component, a week encoding and fit on *model_error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_epiweek(epiweek: int):\n",
    "    \"\"\"\n",
    "    Encode epiweek of the form YYYYWW\n",
    "    \"\"\"\n",
    "    \n",
    "    year = epiweek // 100\n",
    "    week = epiweek % 100\n",
    "    \n",
    "    # Get the limit of weeks in year\n",
    "    n_weeks = pymmwr.mmwr_weeks_in_year(year)\n",
    "    \n",
    "    radian = 2 * np.pi * week / n_weeks\n",
    "    \n",
    "    return np.array([np.sin(radian), np.cos(radian)])\n",
    "\n",
    "weeks = np.array([encode_epiweek(ew) for ew in yi[:, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split based on year\n",
    "We take items before a certain epiweek as train and rest as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = yi[:, 0] < TEST_SPLIT_THRESH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def res_mod(n_input):\n",
    "    \"\"\"\n",
    "    Return an error fit model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape=(n_input,)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    # Return the error\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model generator\n",
    "def gen_model():\n",
    "    return res_mod(3)\n",
    "\n",
    "def train_model(\n",
    "    model, train_data, val_data,\n",
    "    batch_size=64, epochs=100\n",
    "):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "\n",
    "    if val_data is not None:\n",
    "        callbacks = [EarlyStopping(monitor=\"val_loss\", patience=4, mode=\"auto\")]\n",
    "    else:\n",
    "        callbacks = []\n",
    "\n",
    "    history = model.fit(train_data[0],\n",
    "                        train_data[1],\n",
    "                        batch_size=batch_size, epochs=epochs,\n",
    "                        verbose=0,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=val_data)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate([component_out[train_indices][:, None], weeks[train_indices]], axis=1)\n",
    "y_train = component_error[train_indices]\n",
    "yi_train = yi[train_indices]\n",
    "\n",
    "cv_metadata = u.cv_train_loso(\n",
    "    gen_model, train_model,\n",
    "    X_train, y_train, yi_train\n",
    ")\n",
    "u.cv_plot(cv_metadata)\n",
    "cv_report = u.cv_report(cv_metadata)\n",
    "cv_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gen_model()\n",
    "final_epochs = int(cv_report[\"epochs\"][-1])\n",
    "final_history = train_model(model, (X_train, y_train), None, epochs=final_epochs)\n",
    "final_loss = final_history.history[\"loss\"][-1]\n",
    "plt.plot(final_history.history[\"loss\"])\n",
    "final_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regions = [\"nat\", *[f\"hhs{i}\" for i in range(1, 11)], None]\n",
    "\n",
    "mdls = [component.name, \"res-fit\"]\n",
    "\n",
    "eval_df = {mdl: [] for mdl in mdls}\n",
    "\n",
    "for region in regions:\n",
    "    if region is None:\n",
    "        eval_indices = ~train_indices\n",
    "    else:\n",
    "        eval_indices = (~train_indices) & (yi[:, 1] == region)\n",
    "        \n",
    "    component_dist = component.data[eval_indices]\n",
    "    model_in = np.concatenate([component_out[eval_indices][:, None], weeks[eval_indices]], axis=1) \n",
    "    rf_dist = udists.shift_dists(component_dist, model.predict(model_in)[:, 0])\n",
    "\n",
    "    dists = [\n",
    "        component_dist,\n",
    "        rf_dist\n",
    "    ]\n",
    "    y_one_hot = udists.actual_to_one_hot(y[eval_indices])\n",
    "    \n",
    "    for name, output in zip(mdls, dists):\n",
    "        eval_df[name].append(losses.mean_cat_cross(y_one_hot, output))\n",
    "        \n",
    "eval_df = pd.DataFrame(eval_df)\n",
    "eval_df.index = [*regions[:-1], \"all\"]\n",
    "eval_df = eval_df[mdls]\n",
    "\n",
    "# Save results\n",
    "output_dir = u.ensure_dir(f\"../results/{EXP_NAME}\")\n",
    "u.save_exp_summary(model, cv_report, {\n",
    "    \"loss\": final_loss,\n",
    "    \"epochs\": final_epochs\n",
    "}, f\"{output_dir}/{WEEK_NUMBER}_summary.txt\")\n",
    "eval_df.to_csv(f\"{output_dir}/{WEEK_NUMBER}_eval.csv\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
